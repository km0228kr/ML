{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. 텍스트 사전 준비 작업(텍스트 전처리)- 텍스트 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텍스트 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 3\n",
      "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "text_sample= 'The Matrix is everywhere its all around us, here even in this room. \\\n",
    "               You can see it out your window or on your television. \\\n",
    "               You feel it when you go to work, or go to church or pay your taxes.'\n",
    "sentences=sent_tokenize(text=text_sample)\n",
    "print(type(sentences),len(sentences))\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 15\n",
      "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "sentence= 'The Matrix is everywhere its all around us, here even in this room.'\n",
    "words=word_tokenize(sentence)\n",
    "print(type(words),len(words))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 3\n",
      "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "#여러개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화 만드는 함수 생성\n",
    "def tokenize_text(text):\n",
    "    \n",
    "    # 문장별로 분리 토큰\n",
    "    sentences = sent_tokenize(text)\n",
    "    # 분리된 문장별 단어 토큰화\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    return word_tokens\n",
    "\n",
    "#여러 문장들에 대해 문장별 단어 토큰화 수행. \n",
    "word_tokens = tokenize_text(text_sample)\n",
    "print(type(word_tokens),len(word_tokens))\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords(불용어) 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 stop words 갯수 :  179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "print('영어 stop words 갯수 : ', len(nltk.corpus.stopwords.words('english')))\n",
    "print(nltk.corpus.stopwords.words('english')[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "all_tokens=[]\n",
    "#위 예제의 3개의 문장별로 얻은 word_tokens list에 대해 stop word 제거 Loop\n",
    "for sentence in word_tokens:\n",
    "    filtered_words=[]\n",
    "    #개별 문장별로 tokenize된 sentence list에 대해 stop word 제거 loop\n",
    "    for word in sentence:\n",
    "        #소문자로 변환\n",
    "        word=word.lower()\n",
    "        #tokenize된 개별 word가 stop words들의 단어에 포함되지 않으면 word_tokens에 추가\n",
    "        if word not in stopwords:\n",
    "            filtered_words.append(word)\n",
    "    all_tokens.append(filtered_words)\n",
    "    \n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stemming과 Lemmatization\n",
    "- 문법적, 의미적으로 변화하는 단어의 원형 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work work work\n",
      "amus amus amus\n",
      "happy happiest\n",
      "fant fanciest\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer=LancasterStemmer()\n",
    "\n",
    "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
    "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
    "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
    "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amuse amuse amuse\n",
      "happy happy\n",
      "fancy fancy\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemma=WordNetLemmatizer()\n",
    "print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))\n",
    "print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))\n",
    "print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Bag of Words - BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 희소 행렬 - COO 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dense=np.array([[3,0,1],[0,2,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "# 0이 아닌 데이터 추출\n",
    "data=np.array([3,1,2])\n",
    "\n",
    "# 행 위치와 열 위치를 각각 array로 생성\n",
    "row_pos=np.array([0,0,1])\n",
    "col_pos=np.array([0,2,1])\n",
    "\n",
    "# sparse 패키지의 coo_matrix을 이용하여 COO 형식으로 희소 행렬 생성\n",
    "sparse_coo=sparse.coo_matrix((data, (row_pos,col_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1],\n",
       "       [0, 2, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_coo.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n",
      "[[0 0 1 0 0 5]\n",
      " [1 4 0 3 2 5]\n",
      " [0 6 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 7 0 8]\n",
      " [1 0 0 0 0 0]]\n",
      "CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n",
      "[[0 0 1 0 0 5]\n",
      " [1 4 0 3 2 5]\n",
      " [0 6 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 7 0 8]\n",
      " [1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "dense2 = np.array([[0,0,1,0,0,5],\n",
    "             [1,4,0,3,2,5],\n",
    "             [0,6,0,3,0,0],\n",
    "             [2,0,0,0,0,0],\n",
    "             [0,0,0,7,0,8],\n",
    "             [1,0,0,0,0,0]])\n",
    "\n",
    "# 0이 아닌 데이터 추출\n",
    "data2=np.array([1,5,1,4,3,2,5,6,3,2,7,8,1])\n",
    "\n",
    "# 행 위치와 열 위치를 각각 array로 생성\n",
    "row_pos = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5])\n",
    "col_pos = np.array([2, 5, 0, 1, 3, 4, 5, 1, 3, 0, 3, 5, 0])\n",
    "\n",
    "# COO 형식으로 변환\n",
    "sparse_coo=sparse.coo_matrix((data2, (row_pos,col_pos)))\n",
    "\n",
    "# 행 위치 배열의 고유한 값들의 시작 위치 인덱스를 배열로 생성\n",
    "row_pos_ind=np.array([0,2,7,9,10,12,13])\n",
    "\n",
    "# CSR 형식으로 변환\n",
    "sparse_csr=sparse.csr_matrix((data2,col_pos,row_pos_ind))\n",
    "\n",
    "print('COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n",
    "print(sparse_coo.toarray())\n",
    "print('CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n",
    "print(sparse_csr.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense3 = np.array([[0,0,1,0,0,5],\n",
    "             [1,4,0,3,2,5],\n",
    "             [0,6,0,3,0,0],\n",
    "             [2,0,0,0,0,0],\n",
    "             [0,0,0,7,0,8],\n",
    "             [1,0,0,0,0,0]])\n",
    "\n",
    "coo = sparse.coo_matrix(dense3)\n",
    "csr = sparse.csr_matrix(dense3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 텍스트 분류 실습 : 20 뉴스 그룹 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news_data=fetch_20newsgroups(subset='all',random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 클래스의 값과 분포도 \n",
      " 0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "dtype: int64\n",
      "target 클래스의 이름들 \n",
      " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('target 클래스의 값과 분포도 \\n',pd.Series(news_data.target).value_counts().sort_index())\n",
    "print('target 클래스의 이름들 \\n',news_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
      "Subject: Re: Observation re: helmets\n",
      "Organization: Sun Microsystems, RTP, NC\n",
      "Lines: 21\n",
      "Distribution: world\n",
      "Reply-To: egreen@east.sun.com\n",
      "NNTP-Posting-Host: laser.east.sun.com\n",
      "\n",
      "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
      "> \n",
      "> The question for the day is re: passenger helmets, if you don't know for \n",
      ">certain who's gonna ride with you (like say you meet them at a .... church \n",
      ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
      ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
      ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
      ">passenger? \n",
      "\n",
      "If your primary concern is protecting the passenger in the event of a\n",
      "crash, have him or her fitted for a helmet that is their size.  If your\n",
      "primary concern is complying with stupid helmet laws, carry a real big\n",
      "spare (you can put a big or small head in a big helmet, but not in a\n",
      "small one).\n",
      "\n",
      "---\n",
      "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
      "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
      "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
      " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "학습 데이터 크기 11314, 테스트 데이터 크기 7532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# subset='train'으로 학습용(Train) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "train_news=fetch_20newsgroups(subset='train',remove=('headers','footers','quotes'),random_state=156)\n",
    "X_train=train_news.data\n",
    "y_train=train_news.target\n",
    "print(type(X_train))\n",
    "\n",
    "# subset='test'으로 테스트(Test) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "test_news=fetch_20newsgroups(subset='test',remove=('headers','footers','quotes'),random_state=156)\n",
    "X_test=test_news.data\n",
    "y_test=test_news.target\n",
    "print('학습 데이터 크기 {0}, 테스트 데이터 크기 {1}'.format(len(train_news.data),len(test_news.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 Text의 CountVectorizere Shape :  (11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectorizer으로 feature extraction 변환 수행\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(X_train)\n",
    "X_train_cnt_vect=cnt_vect.transform(X_train)\n",
    "\n",
    "# 학습 데이터로 fit된 CountVectorizer을 이용하여 테스트 데이터를 feature extraction 변환 수행\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
    "\n",
    "print('학습 데이터 Text의 CountVectorizere Shape : ',X_train_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorized LogisticRegression의 예측 정확도는 0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic Regression을 이용하여 학습/예측/평가 수행\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect,y_train)\n",
    "pred=lr_clf.predict(X_test_cnt_vect)\n",
    "print('CountVectorized LogisticRegression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression 의 예측 정확도는 0.674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환. \n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect , y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression의 예측 정확도는 0.692\n"
     ]
    }
   ],
   "source": [
    "# stop words 필터링을 추가하고 ngram을 기본(1,1)에서 (1,2)로 변경하여 Feature Vectorization 적용.\n",
    "tfidf_vect=TfidfVectorizer(stop_words='english',ngram_range=(1,2),max_df=300)\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect=tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect=tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect,y_train)\n",
    "pred=lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 38.6min finished\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best C parameters :  {'C': 10}\n",
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 최적 C 값 도출 튜닝 수행. CV는 3 Fold셋으로 설정. \n",
    "params= {'C':[0.01,0.1,1,5,10]}\n",
    "grid_cv_lr=GridSearchCV(lr_clf,param_grid=params,cv=3,scoring='accuracy',verbose=1)\n",
    "grid_cv_lr.fit(X_train_tfidf_vect,y_train)\n",
    "print('Logistic Regression best C parameters : ',grid_cv_lr.best_params_)\n",
    "\n",
    "# 최적 C 값으로 학습된 grid_cv로 예측 수행하고 정확도 평가\n",
    "pred=grid_cv_lr.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline을 통한 Logistic Regression의 예측 정확도는 0.701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TfidfVectorizer 객체를 tfidf_vect 객체명으로, LogisticRegression객체를 lr_clf 객체명으로 생성하는 Pipeline생성\n",
    "pipeline=Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english',ngram_range=(1,2),max_df=300)),\n",
    "    ('lr_clf',LogisticRegression(C=10))\n",
    "])\n",
    "\n",
    "# 별도의 TfidfVectorizer객체의 fit_transform( )과 LogisticRegression의 fit(), predict( )가 필요 없음. \n",
    "# pipeline의 fit( ) 과 predict( ) 만으로 한꺼번에 Feature Vectorization과 ML 학습/예측이 가능. \n",
    "pipeline.fit(X_train,y_train)\n",
    "pred=pipeline.predict(X_test)\n",
    "print('Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline=Pipeline([\n",
    "    ('tfidf_vect',TfidfVectorizer(stop_words='english')),\n",
    "    ('lr_clf',LogisticRegression())\n",
    "])\n",
    "\n",
    "# Pipeline에 기술된 각각의 객체 변수에 언더바(_)2개를 연달아 붙여 GridSearchCV에 사용될 \n",
    "# 파라미터/하이퍼 파라미터 이름과 값을 설정. . \n",
    "params= {'tfidf_vect__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "        'tfidf_vect__max_df':[100,300,700],\n",
    "        'lr_clf__C':[1,5,10]\n",
    "}\n",
    "\n",
    "# GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
    "grid_cv_pipe=GridSearchCV(pipeline,param_grid=params,cv=3,scoring='accuracy',verbose=1)\n",
    "grid_cv_pipe.fit(X_train,y_train)\n",
    "print(grid_cv_pipe.best_params_, grid_cv_pipe.best_score_)\n",
    "\n",
    "pred=grid_cv_pipe.predict(X_test)\n",
    "print('Pipeline을 통한 Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review_df=pd.read_csv('labeledTrainData.tsv',header=0, sep=\"\\t\", quoting=3)\n",
    "review_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- id : 각 데이터의 id\n",
    "- sentiment : 1은 긍정, 0은 부정적 평가\n",
    "- review : 영화평의 텍스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"
     ]
    }
   ],
   "source": [
    "print(review_df['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# <br> html 태그는 replace 함수로 공백으로 변환\n",
    "review_df['review']=review_df['review'].str.replace('<br />', ' ')\n",
    "\n",
    "# 파이썬의 정규 표현식 모듈인 re를 이용하여 영어 문자열이 아닌 문자는 모두 공백으로 변환\n",
    "review_df['review']=review_df['review'].apply(lambda x : re.sub(\"[^a-zA-Z]\", \" \", x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17500, 1), (7500, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_df=review_df['sentiment']\n",
    "feature_df=review_df.drop(['id','sentiment'],axis=1,inplace=False)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(feature_df,class_df,test_size=0.3,random_state=156)\n",
    "\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도는 0.8860, ROC-AUC는 0.9503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 스톱 워드는 English, filtering, ngram은 (1,2)로 설정해 CountVectorization수행. \n",
    "# LogisticRegression의 C는 10으로 설정.\n",
    "pipeline=Pipeline([\n",
    "    ('cnt_vect', CountVectorizer(stop_words='english',ngram_range=(1,2))),\n",
    "    ('lr_clf',LogisticRegression(C=10))])\n",
    "\n",
    "# Pipeline 객체를 이용하여 fit(), predict()로 학습/예측 수행, predict_proba()는 roc_auc때문에 수행\n",
    "pipeline.fit(X_train['review'],y_train)\n",
    "pred=pipeline.predict(X_test['review'])\n",
    "pred_probs=pipeline.predict_proba(X_test['review'])[:,1]\n",
    "\n",
    "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test,pred),roc_auc_score(y_test,pred_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도는 0.8936, ROC-AUC는 0.9598\n"
     ]
    }
   ],
   "source": [
    "# 스톱 워드는 english, filtering, ngram은 (1,2)로 설정해 TF-IDF 벡터화 수행. \n",
    "# LogisticRegression의 C는 10으로 설정. \n",
    "pipeline=Pipeline([\n",
    "    ('tfidf_vect',TfidfVectorizer(stop_words='english',ngram_range=(1,2) )),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "\n",
    "pipeline.fit(X_train['review'],y_train)\n",
    "pred=pipeline.predict(X_test['review'])\n",
    "pred_probs=pipeline.predict_proba(X_test['review'])[:,1]\n",
    "\n",
    "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test ,pred),\n",
    "                                         roc_auc_score(y_test, pred_probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비지도학습 기반 감성분석\n",
    "#### SentiWordNet을 이용한 감성분석\n",
    "\n",
    "- WordNet Synset과 SentiWordNet SentiSynset 클래스의 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\이신행\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets() 반환 type :  <class 'list'>\n",
      "synsets() 반환 값 개수 :  18\n",
      "synsets() 반환 값 :  [Synset('present.n.01'), Synset('present.n.02'), Synset('present.n.03'), Synset('show.v.01'), Synset('present.v.02'), Synset('stage.v.01'), Synset('present.v.04'), Synset('present.v.05'), Synset('award.v.01'), Synset('give.v.08'), Synset('deliver.v.01'), Synset('introduce.v.01'), Synset('portray.v.04'), Synset('confront.v.03'), Synset('present.v.12'), Synset('salute.v.06'), Synset('present.a.01'), Synset('present.a.02')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "term='present'\n",
    "\n",
    "# present라는 단어로 wordnet의 synsets 생성\n",
    "synsets=wn.synsets(term)\n",
    "print('synsets() 반환 type : ', type(synsets))\n",
    "print('synsets() 반환 값 개수 : ', len(synsets))\n",
    "print('synsets() 반환 값 : ',synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Synset name :  present.n.01 #####\n",
      "POS : noun.time\n",
      "Definition: the period of time that is happening now; any continuous stretch of time including the moment of speech\n",
      "Lemmas: ['present', 'nowadays']\n",
      "##### Synset name :  present.n.02 #####\n",
      "POS : noun.possession\n",
      "Definition: something presented as a gift\n",
      "Lemmas: ['present']\n",
      "##### Synset name :  present.n.03 #####\n",
      "POS : noun.communication\n",
      "Definition: a verb tense that expresses actions or states at the time of speaking\n",
      "Lemmas: ['present', 'present_tense']\n",
      "##### Synset name :  show.v.01 #####\n",
      "POS : verb.perception\n",
      "Definition: give an exhibition of to an interested audience\n",
      "Lemmas: ['show', 'demo', 'exhibit', 'present', 'demonstrate']\n",
      "##### Synset name :  present.v.02 #####\n",
      "POS : verb.communication\n",
      "Definition: bring forward and present to the mind\n",
      "Lemmas: ['present', 'represent', 'lay_out']\n",
      "##### Synset name :  stage.v.01 #####\n",
      "POS : verb.creation\n",
      "Definition: perform (a play), especially on a stage\n",
      "Lemmas: ['stage', 'present', 'represent']\n",
      "##### Synset name :  present.v.04 #####\n",
      "POS : verb.possession\n",
      "Definition: hand over formally\n",
      "Lemmas: ['present', 'submit']\n",
      "##### Synset name :  present.v.05 #####\n",
      "POS : verb.stative\n",
      "Definition: introduce\n",
      "Lemmas: ['present', 'pose']\n",
      "##### Synset name :  award.v.01 #####\n",
      "POS : verb.possession\n",
      "Definition: give, especially as an honor or reward\n",
      "Lemmas: ['award', 'present']\n",
      "##### Synset name :  give.v.08 #####\n",
      "POS : verb.possession\n",
      "Definition: give as a present; make a gift of\n",
      "Lemmas: ['give', 'gift', 'present']\n",
      "##### Synset name :  deliver.v.01 #####\n",
      "POS : verb.communication\n",
      "Definition: deliver (a speech, oration, or idea)\n",
      "Lemmas: ['deliver', 'present']\n",
      "##### Synset name :  introduce.v.01 #####\n",
      "POS : verb.communication\n",
      "Definition: cause to come to know personally\n",
      "Lemmas: ['introduce', 'present', 'acquaint']\n",
      "##### Synset name :  portray.v.04 #####\n",
      "POS : verb.creation\n",
      "Definition: represent abstractly, for example in a painting, drawing, or sculpture\n",
      "Lemmas: ['portray', 'present']\n",
      "##### Synset name :  confront.v.03 #####\n",
      "POS : verb.communication\n",
      "Definition: present somebody with something, usually to accuse or criticize\n",
      "Lemmas: ['confront', 'face', 'present']\n",
      "##### Synset name :  present.v.12 #####\n",
      "POS : verb.communication\n",
      "Definition: formally present a debutante, a representative of a country, etc.\n",
      "Lemmas: ['present']\n",
      "##### Synset name :  salute.v.06 #####\n",
      "POS : verb.communication\n",
      "Definition: recognize with a gesture prescribed by a military regulation; assume a prescribed position\n",
      "Lemmas: ['salute', 'present']\n",
      "##### Synset name :  present.a.01 #####\n",
      "POS : adj.all\n",
      "Definition: temporal sense; intermediate between past and future; now existing or happening or in consideration\n",
      "Lemmas: ['present']\n",
      "##### Synset name :  present.a.02 #####\n",
      "POS : adj.all\n",
      "Definition: being or existing in a specified place\n",
      "Lemmas: ['present']\n"
     ]
    }
   ],
   "source": [
    "for synset in synsets :\n",
    "    print('##### Synset name : ', synset.name(),'#####')\n",
    "    print('POS :',synset.lexname())\n",
    "    print('Definition:',synset.definition())\n",
    "    print('Lemmas:',synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree  lion  tiger   cat   dog\n",
       "tree   1.00  0.07   0.07  0.08  0.12\n",
       "lion   0.07  1.00   0.33  0.25  0.17\n",
       "tiger  0.07  0.33   1.00  0.25  0.17\n",
       "cat    0.08  0.25   0.25  1.00  0.20\n",
       "dog    0.12  0.17   0.17  0.20  1.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# synset 객체를 단어별로 생성\n",
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "entities= [tree,lion,tiger,cat,dog]\n",
    "similarities=[]\n",
    "entity_names=[entity.name().split('.')[0] for entity in entities]\n",
    "\n",
    "# 단어별 synset 들을 iteration하면서 다른 단어들의 synset과 유사도를 측정\n",
    "for entity in entities:\n",
    "    similarity = [ round(entity.path_similarity(compared_entity), 2)  for compared_entity in entities ]\n",
    "    similarities.append(similarity)\n",
    "    \n",
    "# 개별 단어별 synset과 다른 단어의 synset과의 유사도를 DataFrame형태로 저장\n",
    "similarity_df=pd.DataFrame(similarities,columns=entity_names, index=entity_names)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti_synsets() 반환 type :  <class 'list'>\n",
      "senti_synsets() 반환 값 갯수: 11\n",
      "senti_synsets() 반환 값 : [SentiSynset('decelerate.v.01'), SentiSynset('slow.v.02'), SentiSynset('slow.v.03'), SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08'), SentiSynset('slowly.r.01'), SentiSynset('behind.r.03')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "senti_synsets = list(swn.senti_synsets('slow'))\n",
    "print('senti_synsets() 반환 type : ', type(senti_synsets))\n",
    "print('senti_synsets() 반환 값 갯수:', len(senti_synsets))\n",
    "print('senti_synsets() 반환 값 :', senti_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father 긍정감성 지수:  0.0\n",
      "father 부정감성 지수:  0.0\n",
      "father 객관성 지수:  1.0\n",
      "\n",
      "\n",
      "fabulous 긍정감성 지수:  0.875\n",
      "fabulous 부정감성 지수:  0.125\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "father = swn.senti_synset('father.n.01')\n",
    "print('father 긍정감성 지수: ', father.pos_score())\n",
    "print('father 부정감성 지수: ', father.neg_score())\n",
    "print('father 객관성 지수: ', father.obj_score())\n",
    "print('\\n')\n",
    "fabulous = swn.senti_synset('fabulous.a.01')\n",
    "print('fabulous 긍정감성 지수: ',fabulous .pos_score())\n",
    "print('fabulous 부정감성 지수: ',fabulous .neg_score())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# 간단한 NLTK PennTreebank Tag을 기반으로 Wordnet기반의 품사 Tag로 변환\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "def swn_polarity(text):\n",
    "    # 감성 지수 초기화\n",
    "    sentiment=0.0\n",
    "    tokens_count=0\n",
    "    \n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    raw_sentences=sent_tokenize(text)\n",
    "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산 \n",
    "    for raw_sentence in raw_sentences:\n",
    "        # NLTK 기반의 품사 태깅 문장 ㅊ출\n",
    "        tagged_sentence=pos_tag(word_tokenize(raw_sentence))\n",
    "        for word, tag in tagged_sentence:\n",
    "            \n",
    "            # Wordnet 기반 품사 태깅과 어근 추출\n",
    "            wn_tag=penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN , wn.ADJ, wn.ADV):\n",
    "                continue\n",
    "            lemma = lemmatizer.lemmatize(word,pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성. \n",
    "            synsets=wn.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
    "            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산. \n",
    "            synsets=synsets[0]\n",
    "            swn_synset=swn.senti_synset(synset.name())\n",
    "            sentiment +=(swn_synset.pos_score() - swn_synset.neg_score())\n",
    "            tokens_count+=1\n",
    "            \n",
    "    if not tokens_count:\n",
    "        return 0\n",
    "    \n",
    "    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
    "    if sentiment >= 0 :\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'review_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-67403c0b74e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreview_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preds'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mswn_polarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'review_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "review_df['preds'] = review_df['review'].apply( lambda x : swn_polarity(x) )\n",
    "y_target = review_df['sentiment'].values\n",
    "preds = review_df['preds'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score \n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "print(confusion_matrix( y_target, preds))\n",
    "print(\"정확도:\", np.round(accuracy_score(y_target , preds), 4))\n",
    "print(\"정밀도:\", np.round(precision_score(y_target , preds),4))\n",
    "print(\"재현율:\", np.round(recall_score(y_target, preds), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'senti_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b862f7bcec22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msenti_analyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msenti_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msenti_analyzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msenti_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'senti_score' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "senti_analyzer=SentimentIntensityAnalyzer()\n",
    "senti_score(senti_analyzer.polarity_scores(review_df['review'][0]))\n",
    "print(senti_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_polarity(review,threshold=0.1):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    \n",
    "    # compound 값에 기반하여 threshold 입력값보다 크면 1, 그렇지 않으면 0을 반환 \n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 1 if agg_score >= threshold else 0\n",
    "    return final_sentiment\n",
    "\n",
    "# apply lambda 식을 이용하여 레코드별로 vader_polarity( )를 수행하고 결과를 'vader_preds'에 저장\n",
    "review_df['vader_preds'] = review_df['review'].apply( lambda x : vader_polarity(x, 0.1) )\n",
    "y_target = review_df['sentiment'].values\n",
    "vader_preds = review_df['vader_preds'].values\n",
    "\n",
    "print(confusion_matrix( y_target, vader_preds))\n",
    "print(\"정확도:\", np.round(accuracy_score(y_target , vader_preds),4))\n",
    "print(\"정밀도:\", np.round(precision_score(y_target , vader_preds),4))\n",
    "print(\"재현율:\", np.round(recall_score(y_target, vader_preds),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. 토픽 모델링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Shape :  (7862, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 의학, 우주 주제를 추출.\n",
    "cats=['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
    "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med'  ]\n",
    "\n",
    "# 위에서 cats변수로 기재된 category만 추출. fetch_20newsgroups()의 categories에 cats 입력\n",
    "# subsets = 로드할 데이터(train,test,all중 default : train)\n",
    "news_df=fetch_20newsgroups(subset='all',remove=('headers','footers','quotes'),\n",
    "                          categories=cats,random_state=0)\n",
    "\n",
    "# LDA는 Count기반 Vectorizer만 적용\n",
    "count_vect=CountVectorizer(max_df=0.95, max_features=1000,min_df=2,stop_words='english',ngram_range=(1,2))\n",
    "feat_vect=count_vect.fit_transform(news_df.data)\n",
    "print('CountVectorizer Shape : ',feat_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=8, random_state=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda=LatentDirichletAllocation(n_components=8,random_state=0)\n",
    "lda.fit(feat_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.60992018e+01, 1.35626798e+02, 2.15751867e+01, ...,\n",
       "        3.02911688e+01, 8.66830093e+01, 6.79285199e+01],\n",
       "       [1.25199920e-01, 1.44401815e+01, 1.25045596e-01, ...,\n",
       "        1.81506995e+02, 1.25097844e-01, 9.39593286e+01],\n",
       "       [3.34762663e+02, 1.25176265e-01, 1.46743299e+02, ...,\n",
       "        1.25105772e-01, 3.63689741e+01, 1.25025218e-01],\n",
       "       ...,\n",
       "       [3.60204965e+01, 2.08640688e+01, 4.29606813e+00, ...,\n",
       "        1.45056650e+01, 8.33854413e+00, 1.55690009e+01],\n",
       "       [1.25128711e-01, 1.25247756e-01, 1.25005143e-01, ...,\n",
       "        9.17278769e+01, 1.25177668e-01, 3.74575887e+01],\n",
       "       [5.49258690e+01, 4.47009532e+00, 9.88524814e+00, ...,\n",
       "        4.87048440e+01, 1.25034678e-01, 1.25074632e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lda.components_.shape)\n",
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic # 0\n",
      "year 10 game medical health team 12 20 disease cancer 1993 games years patients good\n",
      "Topic # 1\n",
      "don just like know people said think time ve didn right going say ll way\n",
      "Topic # 2\n",
      "image file jpeg program gif images output format files color entry 00 use bit 03\n",
      "Topic # 3\n",
      "like know don think use does just good time book read information people used post\n",
      "Topic # 4\n",
      "armenian israel armenians jews turkish people israeli jewish government war dos dos turkey arab armenia 000\n",
      "Topic # 5\n",
      "edu com available graphics ftp data pub motif mail widget software mit information version sun\n",
      "Topic # 6\n",
      "god people jesus church believe christ does christian say think christians bible faith sin life\n",
      "Topic # 7\n",
      "use dos thanks windows using window does display help like problem server need know run\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        print('Topic #',topic_index)\n",
    "\n",
    "        # components_ array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array index를 반환. \n",
    "        topic_word_indexes = topic.argsort()[::-1]\n",
    "        top_indexes=topic_word_indexes[:no_top_words]\n",
    "        \n",
    "        # top_indexes대상인 index별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
    "        feature_concat = ' '.join([feature_names[i] for i in top_indexes])                \n",
    "        print(feature_concat)\n",
    "\n",
    "# CountVectorizer객체내의 전체 word들의 명칭을 get_features_names( )를 통해 추출\n",
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "# Topic별 가장 연관도가 높은 word를 15개만 추출\n",
    "display_topics(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 문서 군집화 소개와 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0   accuracy_garmin_nuvi_255W_gps   \n",
       "1  bathroom_bestwestern_hotel_sfo   \n",
       "2      battery-life_amazon_kindle   \n",
       "3      battery-life_ipod_nano_8gb   \n",
       "4     battery-life_netbook_1005ha   \n",
       "\n",
       "                                        opinion_text  \n",
       "0                                                ...  \n",
       "1                                                ...  \n",
       "2                                                ...  \n",
       "3                                                ...  \n",
       "4                                                ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "path=r'C:\\Users\\이신행\\OneDrive\\바탕 화면\\OpinosisDataset1.0\\OpinosisDataset1.0\\topics'\n",
    "\n",
    "# path로 지정한 디렉토리 밑에 있는 모든 .data 파일들의 파일명을 리스트로 취합\n",
    "all_files = glob.glob(os.path.join(path, \"*.data\"))    \n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "# 개별 파일들의 파일명은 filename_list 리스트로 취합, \n",
    "# 개별 파일들의 파일내용은 DataFrame로딩 후 다시 string으로 변환하여 opinion_text 리스트로 취합 \n",
    "for file_ in all_files:\n",
    "    # 개별 파일을 읽어서 DataFrame으로 생성 \n",
    "    df = pd.read_table(file_,index_col=None, header=0,encoding='latin1')\n",
    "    \n",
    "    # 절대경로로 주어진 file 명을 가공. 만일 Linux에서 수행시에는 아래 \\\\를 / 변경. 맨 마지막 .data 확장자도 제거\n",
    "    filename_ = file_.split('\\\\')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "\n",
    "    #파일명 리스트와 파일내용 리스트에 파일명과 파일 내용을 추가. \n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "\n",
    "# 파일명 리스트와 파일내용 리스트를  DataFrame으로 생성\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "remove_punct_dict=dict((ord(punct),None) for punct in string.punctuation) # string.punctuation은 구두점 없앰\n",
    "lemmar=WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmar.lemmatize(token) for token in tokens]\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english',\\\n",
    "                          ngram_range=(1,2),min_df=0.05,max_df=0.85)\n",
    "\n",
    "# opinion_text 컬럼값으로 feature vectorization 수행\n",
    "feature_vect=tfidf_vect.fit_transform(document_df['opinion_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 5개 집합으로 군집화 수행. 예제를 위해 동일한 클러스터링 결과 도출용 random_state=0 \n",
    "km_cluster = KMeans(n_clusters=5, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0   accuracy_garmin_nuvi_255W_gps   \n",
       "1  bathroom_bestwestern_hotel_sfo   \n",
       "2      battery-life_amazon_kindle   \n",
       "3      battery-life_ipod_nano_8gb   \n",
       "4     battery-life_netbook_1005ha   \n",
       "\n",
       "                                        opinion_text  cluster_label  \n",
       "0                                                ...              0  \n",
       "1                                                ...              1  \n",
       "2                                                ...              3  \n",
       "3                                                ...              3  \n",
       "4                                                ...              3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df['cluster_label']=cluster_label\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>directions_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>display_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>satellite_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>screen_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>speed_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>transmission_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>updates_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  \\\n",
       "0     accuracy_garmin_nuvi_255W_gps   \n",
       "8   directions_garmin_nuvi_255W_gps   \n",
       "9      display_garmin_nuvi_255W_gps   \n",
       "33   satellite_garmin_nuvi_255W_gps   \n",
       "34      screen_garmin_nuvi_255W_gps   \n",
       "43       speed_garmin_nuvi_255W_gps   \n",
       "47   transmission_toyota_camry_2007   \n",
       "48     updates_garmin_nuvi_255W_gps   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "0                                                 ...              0  \n",
       "8                                                 ...              0  \n",
       "9                                                 ...              0  \n",
       "33                                                ...              0  \n",
       "34                                                ...              0  \n",
       "43                                                ...              0  \n",
       "47                                                ...              0  \n",
       "48                                                ...              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==0].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>food_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>food_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>free_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>location_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>location_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>parking_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>price_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>room_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rooms_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rooms_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>service_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>service_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>service_swissotel_hotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>staff_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>staff_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  \\\n",
       "1    bathroom_bestwestern_hotel_sfo   \n",
       "13          food_holiday_inn_london   \n",
       "14           food_swissotel_chicago   \n",
       "15       free_bestwestern_hotel_sfo   \n",
       "20   location_bestwestern_hotel_sfo   \n",
       "21      location_holiday_inn_london   \n",
       "24    parking_bestwestern_hotel_sfo   \n",
       "28         price_holiday_inn_london   \n",
       "32          room_holiday_inn_london   \n",
       "30      rooms_bestwestern_hotel_sfo   \n",
       "31          rooms_swissotel_chicago   \n",
       "38    service_bestwestern_hotel_sfo   \n",
       "39       service_holiday_inn_london   \n",
       "40  service_swissotel_hotel_chicago   \n",
       "45      staff_bestwestern_hotel_sfo   \n",
       "46          staff_swissotel_chicago   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "1                                                 ...              1  \n",
       "13                                                ...              1  \n",
       "14                                                ...              1  \n",
       "15                                                ...              1  \n",
       "20                                                ...              1  \n",
       "21                                                ...              1  \n",
       "24                                                ...              1  \n",
       "28                                                ...              1  \n",
       "32                                                ...              1  \n",
       "30                                                ...              1  \n",
       "31                                                ...              1  \n",
       "38                                                ...              1  \n",
       "39                                                ...              1  \n",
       "40                                                ...              1  \n",
       "45                                                ...              1  \n",
       "46                                                ...              1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==1].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comfort_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comfort_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gas_mileage_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>interior_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>interior_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mileage_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>performance_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>quality_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>seats_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "6       comfort_honda_accord_2008   \n",
       "7       comfort_toyota_camry_2007   \n",
       "16  gas_mileage_toyota_camry_2007   \n",
       "17     interior_honda_accord_2008   \n",
       "18     interior_toyota_camry_2007   \n",
       "22      mileage_honda_accord_2008   \n",
       "25  performance_honda_accord_2008   \n",
       "29      quality_toyota_camry_2007   \n",
       "37        seats_honda_accord_2008   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "6                                                 ...              2  \n",
       "7                                                 ...              2  \n",
       "16                                                ...              2  \n",
       "17                                                ...              2  \n",
       "18                                                ...              2  \n",
       "22                                                ...              2  \n",
       "25                                                ...              2  \n",
       "29                                                ...              2  \n",
       "37                                                ...              2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==2].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>performance_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sound_ipod_nano_8gb</td>\n",
       "      <td>headphone jack i got a clear case for it a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>video_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename  \\\n",
       "2    battery-life_amazon_kindle   \n",
       "3    battery-life_ipod_nano_8gb   \n",
       "4   battery-life_netbook_1005ha   \n",
       "26   performance_netbook_1005ha   \n",
       "42          sound_ipod_nano_8gb   \n",
       "49          video_ipod_nano_8gb   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "2                                                 ...              3  \n",
       "3                                                 ...              3  \n",
       "4                                                 ...              3  \n",
       "26                                                ...              3  \n",
       "42      headphone jack i got a clear case for it a...              3  \n",
       "49                                                ...              3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==3].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>buttons_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>eyesight-issues_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>features_windows7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fonts_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>keyboard_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>navigation_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>price_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>screen_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>screen_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>size_asus_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>speed_windows7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>voice_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "5           buttons_amazon_kindle   \n",
       "10  eyesight-issues_amazon_kindle   \n",
       "11              features_windows7   \n",
       "12            fonts_amazon_kindle   \n",
       "19        keyboard_netbook_1005ha   \n",
       "23       navigation_amazon_kindle   \n",
       "27            price_amazon_kindle   \n",
       "35           screen_ipod_nano_8gb   \n",
       "36          screen_netbook_1005ha   \n",
       "41       size_asus_netbook_1005ha   \n",
       "44                 speed_windows7   \n",
       "50     voice_garmin_nuvi_255W_gps   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "5                                                 ...              4  \n",
       "10                                                ...              4  \n",
       "11                                                ...              4  \n",
       "12                                                ...              4  \n",
       "19                                                ...              4  \n",
       "23                                                ...              4  \n",
       "27                                                ...              4  \n",
       "35                                                ...              4  \n",
       "36                                                ...              4  \n",
       "41                                                ...              4  \n",
       "44                                                ...              4  \n",
       "50                                                ...              4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "document_df[document_df['cluster_label']==4].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>updates_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>speed_windows7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>speed_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sound_ipod_nano_8gb</td>\n",
       "      <td>headphone jack i got a clear case for it a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>size_asus_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>screen_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>screen_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>screen_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>satellite_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>price_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>performance_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>video_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>navigation_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>keyboard_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>voice_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>display_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>directions_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>eyesight-issues_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>features_windows7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fonts_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>buttons_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>food_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>service_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>service_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>food_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>location_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>parking_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>free_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rooms_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rooms_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>staff_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>service_swissotel_hotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>location_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>staff_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>room_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>price_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>transmission_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gas_mileage_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comfort_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comfort_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>quality_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mileage_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>interior_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>interior_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>seats_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>performance_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  \\\n",
       "0     accuracy_garmin_nuvi_255W_gps   \n",
       "48     updates_garmin_nuvi_255W_gps   \n",
       "44                   speed_windows7   \n",
       "43       speed_garmin_nuvi_255W_gps   \n",
       "42              sound_ipod_nano_8gb   \n",
       "41         size_asus_netbook_1005ha   \n",
       "36            screen_netbook_1005ha   \n",
       "35             screen_ipod_nano_8gb   \n",
       "34      screen_garmin_nuvi_255W_gps   \n",
       "33   satellite_garmin_nuvi_255W_gps   \n",
       "27              price_amazon_kindle   \n",
       "26       performance_netbook_1005ha   \n",
       "49              video_ipod_nano_8gb   \n",
       "23         navigation_amazon_kindle   \n",
       "19          keyboard_netbook_1005ha   \n",
       "50       voice_garmin_nuvi_255W_gps   \n",
       "9      display_garmin_nuvi_255W_gps   \n",
       "4       battery-life_netbook_1005ha   \n",
       "3        battery-life_ipod_nano_8gb   \n",
       "2        battery-life_amazon_kindle   \n",
       "8   directions_garmin_nuvi_255W_gps   \n",
       "10    eyesight-issues_amazon_kindle   \n",
       "11                features_windows7   \n",
       "12              fonts_amazon_kindle   \n",
       "5             buttons_amazon_kindle   \n",
       "13          food_holiday_inn_london   \n",
       "39       service_holiday_inn_london   \n",
       "38    service_bestwestern_hotel_sfo   \n",
       "1    bathroom_bestwestern_hotel_sfo   \n",
       "14           food_swissotel_chicago   \n",
       "20   location_bestwestern_hotel_sfo   \n",
       "24    parking_bestwestern_hotel_sfo   \n",
       "15       free_bestwestern_hotel_sfo   \n",
       "31          rooms_swissotel_chicago   \n",
       "30      rooms_bestwestern_hotel_sfo   \n",
       "45      staff_bestwestern_hotel_sfo   \n",
       "40  service_swissotel_hotel_chicago   \n",
       "21      location_holiday_inn_london   \n",
       "46          staff_swissotel_chicago   \n",
       "32          room_holiday_inn_london   \n",
       "28         price_holiday_inn_london   \n",
       "47   transmission_toyota_camry_2007   \n",
       "16    gas_mileage_toyota_camry_2007   \n",
       "6         comfort_honda_accord_2008   \n",
       "7         comfort_toyota_camry_2007   \n",
       "29        quality_toyota_camry_2007   \n",
       "22        mileage_honda_accord_2008   \n",
       "18       interior_toyota_camry_2007   \n",
       "17       interior_honda_accord_2008   \n",
       "37          seats_honda_accord_2008   \n",
       "25    performance_honda_accord_2008   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "0                                                 ...              0  \n",
       "48                                                ...              0  \n",
       "44                                                ...              0  \n",
       "43                                                ...              0  \n",
       "42      headphone jack i got a clear case for it a...              0  \n",
       "41                                                ...              0  \n",
       "36                                                ...              0  \n",
       "35                                                ...              0  \n",
       "34                                                ...              0  \n",
       "33                                                ...              0  \n",
       "27                                                ...              0  \n",
       "26                                                ...              0  \n",
       "49                                                ...              0  \n",
       "23                                                ...              0  \n",
       "19                                                ...              0  \n",
       "50                                                ...              0  \n",
       "9                                                 ...              0  \n",
       "4                                                 ...              0  \n",
       "3                                                 ...              0  \n",
       "2                                                 ...              0  \n",
       "8                                                 ...              0  \n",
       "10                                                ...              0  \n",
       "11                                                ...              0  \n",
       "12                                                ...              0  \n",
       "5                                                 ...              0  \n",
       "13                                                ...              1  \n",
       "39                                                ...              1  \n",
       "38                                                ...              1  \n",
       "1                                                 ...              1  \n",
       "14                                                ...              1  \n",
       "20                                                ...              1  \n",
       "24                                                ...              1  \n",
       "15                                                ...              1  \n",
       "31                                                ...              1  \n",
       "30                                                ...              1  \n",
       "45                                                ...              1  \n",
       "40                                                ...              1  \n",
       "21                                                ...              1  \n",
       "46                                                ...              1  \n",
       "32                                                ...              1  \n",
       "28                                                ...              1  \n",
       "47                                                ...              2  \n",
       "16                                                ...              2  \n",
       "6                                                 ...              2  \n",
       "7                                                 ...              2  \n",
       "29                                                ...              2  \n",
       "22                                                ...              2  \n",
       "18                                                ...              2  \n",
       "17                                                ...              2  \n",
       "37                                                ...              2  \n",
       "25                                                ...              2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 3개의 집합으로 군집화\n",
    "km_cluster=KMeans(n_clusters=3,max_iter=10000,random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label=km_cluster.labels_\n",
    "\n",
    "# 소속 클러스터를 cluster_label 컬럼으로 할당하고 cluster_label값으로 정렬\n",
    "document_df['cluster_label']=cluster_label\n",
    "document_df.sort_values(by='cluster_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 군집 별 핵심 단어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_centers shape :  (3, 4611)\n",
      "[[0.01005322 0.         0.         ... 0.00706287 0.         0.        ]\n",
      " [0.         0.00099499 0.00174637 ... 0.         0.00183397 0.00144581]\n",
      " [0.         0.00092551 0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "cluster_centers=km_cluster.cluster_centers_\n",
    "print('cluster_centers shape : ',cluster_centers.shape)\n",
    "print(cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집별 top n 핵심단어, 그 단어의 중심 위치 상대값, 대상 파일명들을 반환함. \n",
    "def get_cluster_details(cluster_model, cluster_data, feature_names, clusters_num, top_n_features=10):\n",
    "    cluster_details = {}\n",
    "    \n",
    "    # cluster_centers array 의 값이 큰 순으로 정렬된 index 값을 반환\n",
    "    # 군집 중심점(centroid)별 할당된 word 피처들의 거리값이 큰 순으로 값을 구하기 위함.  \n",
    "    centroid_feature_ordered_ind = cluster_model.cluster_centers_.argsort()[:,::-1]\n",
    "    \n",
    "    #개별 군집별로 iteration하면서 핵심단어, 그 단어의 중심 위치 상대값, 대상 파일명 입력\n",
    "    for cluster_num in range(clusters_num):\n",
    "        # 개별 군집별 정보를 담을 데이터 초기화. \n",
    "        cluster_details[cluster_num] = {}\n",
    "        cluster_details[cluster_num]['cluster'] = cluster_num\n",
    "        \n",
    "        # cluster_centers_.argsort()[:,::-1] 로 구한 index 를 이용하여 top n 피처 단어를 구함. \n",
    "        top_feature_indexes = centroid_feature_ordered_ind[cluster_num, :top_n_features]\n",
    "        top_features = [ feature_names[ind] for ind in top_feature_indexes ]\n",
    "        \n",
    "        # top_feature_indexes를 이용해 해당 피처 단어의 중심 위치 상댓값 구함 \n",
    "        top_feature_values = cluster_model.cluster_centers_[cluster_num, top_feature_indexes].tolist()\n",
    "        \n",
    "        # cluster_details 딕셔너리 객체에 개별 군집별 핵심 단어와 중심위치 상대값, 그리고 해당 파일명 입력\n",
    "        cluster_details[cluster_num]['top_features'] = top_features\n",
    "        cluster_details[cluster_num]['top_features_value'] = top_feature_values\n",
    "        filenames = cluster_data[cluster_data['cluster_label'] == cluster_num]['filename']\n",
    "        filenames = filenames.values.tolist()\n",
    "        cluster_details[cluster_num]['filenames'] = filenames\n",
    "        \n",
    "    return cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_details(cluster_details):\n",
    "    for cluster_num, cluster_detail in cluster_details.items():\n",
    "        print('####### Cluster {0}'.format(cluster_num))\n",
    "        print('Top features:', cluster_detail['top_features'])\n",
    "        print('Reviews 파일명 :',cluster_detail['filenames'][:7])\n",
    "        print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Cluster 0\n",
      "Top features: ['screen', 'battery', 'keyboard', 'battery life', 'life', 'kindle', 'direction', 'video', 'size', 'voice']\n",
      "Reviews 파일명 : ['accuracy_garmin_nuvi_255W_gps', 'battery-life_amazon_kindle', 'battery-life_ipod_nano_8gb', 'battery-life_netbook_1005ha', 'buttons_amazon_kindle', 'directions_garmin_nuvi_255W_gps', 'display_garmin_nuvi_255W_gps']\n",
      "==================================================\n",
      "####### Cluster 1\n",
      "Top features: ['room', 'hotel', 'service', 'staff', 'food', 'location', 'bathroom', 'clean', 'price', 'parking']\n",
      "Reviews 파일명 : ['bathroom_bestwestern_hotel_sfo', 'food_holiday_inn_london', 'food_swissotel_chicago', 'free_bestwestern_hotel_sfo', 'location_bestwestern_hotel_sfo', 'location_holiday_inn_london', 'parking_bestwestern_hotel_sfo']\n",
      "==================================================\n",
      "####### Cluster 2\n",
      "Top features: ['interior', 'seat', 'mileage', 'comfortable', 'gas', 'gas mileage', 'transmission', 'car', 'performance', 'quality']\n",
      "Reviews 파일명 : ['comfort_honda_accord_2008', 'comfort_toyota_camry_2007', 'gas_mileage_toyota_camry_2007', 'interior_honda_accord_2008', 'interior_toyota_camry_2007', 'mileage_honda_accord_2008', 'performance_honda_accord_2008']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_names = tfidf_vect.get_feature_names()\n",
    "\n",
    "cluster_details = get_cluster_details(cluster_model=km_cluster, cluster_data=document_df,\\\n",
    "                                  feature_names=feature_names, clusters_num=3, top_n_features=10 )\n",
    "print_cluster_details(cluster_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09 문서 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cos_similarity(v1,v2):\n",
    "    dot_product=np.dot(v1,v2)\n",
    "    l2_norm=(np.sqrt(sum(np.square(v1))) * np.sqrt(sum(np.square(v2))))\n",
    "    similarity=dot_product / l2_norm\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 18)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "doc_list=['if you take the blue pill, the story ends' ,\n",
    "            'if you take the red pill, you stay in Wonderland',\n",
    "            'if you take the red pill, I show you how deep the rabbit hole goes']\n",
    "\n",
    "tfidf_vect_simple=TfidfVectorizer()\n",
    "feature_vect_simple=tfidf_vect_simple.fit_transform(doc_list)\n",
    "print(feature_vect_simple.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 1, 문장 2 Cosine 유사도 : 0.402\n"
     ]
    }
   ],
   "source": [
    "# TFidfVectorizer로 transform()한 결과는 Sparse Matrix이므로 Dense Matrix로 변환.\n",
    "feature_vect_dense=feature_vect_simple.todense()\n",
    "\n",
    "# 첫번째 문장과 두번째 문장의 feature vector  추출\n",
    "vect1=np.array(feature_vect_dense[0]).reshape(-1,)\n",
    "vect2=np.array(feature_vect_dense[1]).reshape(-1,)\n",
    "\n",
    "#첫번째 문장과 두번째 문장의 feature vector로 두개 문장의 Cosine 유사도 추출\n",
    "similarity_simple=cos_similarity(vect1,vect2)\n",
    "print('문장 1, 문장 2 Cosine 유사도 : {0:.3f}'.format(similarity_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 1, 문장 3 Cosine 유사도 : 0.404\n",
      "문장 1, 문장 3 Cosine 유사도 : 0.456\n"
     ]
    }
   ],
   "source": [
    "vect1=np.array(feature_vect_dense[0]).reshape(-1,)\n",
    "vect3=np.array(feature_vect_dense[2]).reshape(-1,)\n",
    "similarity_simple=cos_similarity(vect1,vect3)\n",
    "print('문장 1, 문장 3 Cosine 유사도 : {0:.3f}'.format(similarity_simple))\n",
    "\n",
    "vect2=np.array(feature_vect_dense[1]).reshape(-1,)\n",
    "vect3=np.array(feature_vect_dense[2]).reshape(-1,)\n",
    "similarity_simple=cos_similarity(vect2,vect3)\n",
    "print('문장 1, 문장 3 Cosine 유사도 : {0:.3f}'.format(similarity_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40207758 0.40425045]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_simple_pair=cosine_similarity(feature_vect_simple[0],feature_vect_simple)\n",
    "print(similarity_simple_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40207758 0.40425045]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_simple_pair=cosine_similarity(feature_vect_simple[0], feature_vect_simple[1:])\n",
    "print(similarity_simple_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40207758 0.40425045]\n",
      " [0.40207758 1.         0.45647296]\n",
      " [0.40425045 0.45647296 1.        ]]\n",
      "shape :  (3, 3)\n"
     ]
    }
   ],
   "source": [
    "similarity_simple_pair=cosine_similarity(feature_vect_simple, feature_vect_simple)\n",
    "print(similarity_simple_pair)\n",
    "print('shape : ',similarity_simple_pair.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opinion Review 데이터 셋을 이용한 문서 유사도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "path=r'C:\\Users\\이신행\\OneDrive\\바탕 화면\\OpinosisDataset1.0\\OpinosisDataset1.0\\topics'\n",
    "\n",
    "# path로 지정한 디렉토리 밑에 있는 모든 .data 파일들의 파일명을 리스트로 취합\n",
    "all_files = glob.glob(os.path.join(path, \"*.data\"))    \n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "# 개별 파일들의 파일명은 filename_list 리스트로 취합, \n",
    "# 개별 파일들의 파일내용은 DataFrame로딩 후 다시 string으로 변환하여 opinion_text 리스트로 취합 \n",
    "for file_ in all_files:\n",
    "    # 개별 파일을 읽어서 DataFrame으로 생성 \n",
    "    df = pd.read_table(file_,index_col=None, header=0,encoding='latin1')\n",
    "    \n",
    "    # 절대경로로 주어진 file 명을 가공. 만일 Linux에서 수행시에는 아래 \\\\를 / 변경. 맨 마지막 .data 확장자도 제거\n",
    "    filename_ = file_.split('\\\\')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "\n",
    "    #파일명 리스트와 파일내용 리스트에 파일명과 파일 내용을 추가. \n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "\n",
    "# 파일명 리스트와 파일내용 리스트를  DataFrame으로 생성\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "tfidf_vect=TfidfVectorizer(tokenizer=LemNormalize, stop_words='english', \\\n",
    "                          ngram_range=(1,2),min_df=0.05,max_df=0.85)\n",
    "featrue_vect=tfidf_vect.fit_transform(document_df['opinion_text'])\n",
    "\n",
    "km_cluster=KMeans(n_clusters=3,max_iter=10000,random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label=km_cluster.labels_\n",
    "cluster_centers=km_cluster.cluster_centers_\n",
    "document_df['cluster_label']=cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호텔로 클러스터링 된 문서들의 DataFrame index :  Int64Index([1, 13, 14, 15, 20, 21, 24, 28, 30, 31, 32, 38, 39, 40, 45, 46], dtype='int64')\n",
      "##### 비교 기준 문서명  bathroom_bestwestern_hotel_sfo 와 타 문서 유사도 #####\n",
      "[[1.         0.0430688  0.05221059 0.06189595 0.05846178 0.06193118\n",
      "  0.03638665 0.11742762 0.38038865 0.32619948 0.51442299 0.11282857\n",
      "  0.13989623 0.1386783  0.09518068 0.07049362]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# cluster_label=1인 데이터는 호텔로 클러스터링된 데이터임. DataFrame에서 해당 index를 추출\n",
    "hotel_indexes=document_df[document_df['cluster_label']==1].index\n",
    "print('호텔로 클러스터링 된 문서들의 DataFrame index : ',hotel_indexes)\n",
    "\n",
    "# 호텔로 클러스터링된 데이터 중 첫번째 문서를 추출하여 파일명 표시. \n",
    "comparison_docname=document_df.iloc[hotel_indexes[0]]['filename']\n",
    "print('##### 비교 기준 문서명 ',comparison_docname,'와 타 문서 유사도 #####')\n",
    "\n",
    "''' document_df에서 추출한 Index 객체를 feature_vect로 입력하여 호텔 클러스터링된 feature_vect 추출 \n",
    "이를 이용하여 호텔로 클러스터링된 문서 중 첫번째 문서와 다른 문서간의 코사인 유사도 측정.'''\n",
    "similarity_pair=cosine_similarity(feature_vect[hotel_indexes[0]], feature_vect[hotel_indexes])\n",
    "print(similarity_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'bathroom_bestwestern_hotel_sfo')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# argsort()를 이용하여 앞예제의 첫번째 문서와 타 문서간 유사도가 큰 순으로 정렬한 인덱스 반환하되 자기 자신은 제외.\n",
    "sorted_index=similarity_pair.argsort()[:,::-1]\n",
    "sorted_index=sorted_index[:,1:] # 자기자신 제외\n",
    "\n",
    "# 유사도가 큰 순으로 hotel_indexes를 추출하여 재 정렬.\n",
    "hotel_sorted_indexes=hotel_indexes[sorted_index.reshape(-1)]\n",
    "\n",
    "# 유사도가 큰 순으로 유사도 값을 재정렬하되 자기 자신은 제외\n",
    "hotel_1_sim_value=np.sort(similarity_pair.reshape(-1))[::-1]\n",
    "hotel_1_sim_value=hotel_1_sim_value[1:]\n",
    "\n",
    "# 유사도가 큰 순으로 정렬된 index와 유사도 값을 이용하여 파일명과 유사도값을 seaborn 막대 그래프로 시각화\n",
    "hotel_1_sim_df=pd.DataFrame()\n",
    "hotel_1_sim_df['filename']=document_df.iloc[hotel_sorted_indexes]['filename']\n",
    "hotel_1_sim_df['similarity']=hotel_1_sim_value\n",
    "\n",
    "sns.barplot(x='similarity',y='filename',data=hotel_1_sim_df)\n",
    "plt.title(comparison_docname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 텍스트 분석 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_id : 데이터 id\n",
    "- name : 제품명\n",
    "- item_condition_id : 판매자가 제공하는 제품 상태\n",
    "- category_name : 카테고리명\n",
    "- brand_name : 브랜드 이름\n",
    "- price : 제품 가격, 예측을 위한 타깃 속성\n",
    "- shipping : 배솓비 무료 여부, 1이면 무료, 0이면 유료\n",
    "- item_description : 제품에 대한 설명\n",
    "\n",
    "price가 예측해야 할 타깃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482535, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "mercari_df=pd.read_csv('mercari_train.tsv',sep='\\t')\n",
    "print(mercari_df.shape)\n",
    "mercari_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "피처의 타입과 null 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1482535 entries, 0 to 1482534\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   train_id           1482535 non-null  int64  \n",
      " 1   name               1482535 non-null  object \n",
      " 2   item_condition_id  1482535 non-null  int64  \n",
      " 3   category_name      1476208 non-null  object \n",
      " 4   brand_name         849853 non-null   object \n",
      " 5   price              1482535 non-null  float64\n",
      " 6   shipping           1482535 non-null  int64  \n",
      " 7   item_description   1482531 non-null  object \n",
      "dtypes: float64(1), int64(3), object(4)\n",
      "memory usage: 90.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(mercari_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "price 칼럼 데이터 분포도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='price'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAERCAYAAABrWly6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAASeklEQVR4nO3df5Dcd13H8efLhKIIiJDDqUljApNWM0wL5VpA+VFEIeko8bctHYpYiFXKwDg6rcMMMvIXMjiO0hojZgoKFH9UjU6gOo5apRSSYlualpTQYnu0klCQiqg18PaP/R5sj73bvXRv9+7T52Pm5vb7+X5u99XvXl/57nf3+71UFZKkte9bph1AkjQeFrokNcJCl6RGWOiS1AgLXZIaYaFLUiOmWuhJ9iU5luS2Eef/TJLbkxxO8r6VzidJa0mm+Tn0JC8Evgy8p6qeMWTuNuBPgB+sqi8meWpVHZtETklaC6a6h15V1wNf6B9L8vQkH0pyU5J/TvK93arXAldW1Re7n7XMJanPajyGvhd4fVU9G/gV4Kpu/HTg9CQfTnJjkh1TSyhJq9D6aQfol+TxwPcDf5pkfvix3ff1wDbgPGAT8M9JnlFV/zHhmJK0Kq2qQqf3iuE/quqZA9bNATdW1f8Bdyc5Qq/gD04wnyStWqvqkEtVPUivrH8aID1ndav/EnhxN76B3iGYu6aRU5JWo2l/bPH9wEeAM5LMJbkEuAi4JMktwGFgVzf9OuCBJLcD/wD8alU9MI3ckrQaTfVji5Kk8VlVh1wkSSdvam+KbtiwobZs2TKth5ekNemmm276fFXNDFo3tULfsmULhw4dmtbDS9KalOTfFlvnIRdJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWrEarse+kje99F7Fl33iudsnmASSVo93EOXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjRha6En2JTmW5LZF1l+U5Nbu64YkZ40/piRpmFH20K8Gdiyx/m7gRVV1JvBWYO8YckmSlmnoiUVVdX2SLUusv6Fv8UZg0xhySZKWadzH0C8BPrjYyiS7kxxKcuj48eNjfmhJenQbW6EneTG9Qr98sTlVtbeqZqtqdmZm4B+tliSdpLFcyyXJmcC7gJ1V9cA47lOStDyPeA89yWbgWuCVVXXnI48kSToZQ/fQk7wfOA/YkGQO+HXgMQBVtQd4M/AU4KokACeqanalAkuSBhvlUy4XDln/GuA1Y0skSTopnikqSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqxNBCT7IvybEkty2yPkl+J8nRJLcmOXv8MSVJw4yyh341sGOJ9TuBbd3XbuD3HnksSdJyDS30qroe+MISU3YB76meG4EnJTl1XAElSaMZxzH0jcC9fctz3dg3SbI7yaEkh44fPz6Gh5YkzRtHoWfAWA2aWFV7q2q2qmZnZmbG8NCSpHnjKPQ54LS+5U3AfWO4X0nSMoyj0PcDF3efdnku8KWqun8M9ytJWob1wyYkeT9wHrAhyRzw68BjAKpqD3AAOB84CnwFePVKhZUkLW5ooVfVhUPWF/C6sSWSJJ0UzxSVpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1YqRCT7IjyZEkR5NcMWD9dyT56yS3JDmc5NXjjypJWsrQQk+yDrgS2AlsBy5Msn3BtNcBt1fVWcB5wDuSnDLmrJKkJYyyh34ucLSq7qqqh4BrgF0L5hTwhCQBHg98ATgx1qSSpCWNUugbgXv7lue6sX7vBL4PuA/4BPCGqvrawjtKsjvJoSSHjh8/fpKRJUmDjFLoGTBWC5ZfBtwMfDfwTOCdSZ74TT9UtbeqZqtqdmZmZplRJUlLGaXQ54DT+pY30dsT7/dq4NrqOQrcDXzveCJKkkYxSqEfBLYl2dq90XkBsH/BnHuAlwAk+S7gDOCucQaVJC1t/bAJVXUiyWXAdcA6YF9VHU5yabd+D/BW4Ookn6B3iObyqvr8CuaWJC0wtNABquoAcGDB2J6+2/cBLx1vNEnScnimqCQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNGKnQk+xIciTJ0SRXLDLnvCQ3Jzmc5J/GG1OSNMz6YROSrAOuBH4YmAMOJtlfVbf3zXkScBWwo6ruSfLUFcorSVrEKHvo5wJHq+quqnoIuAbYtWDOK4Brq+oegKo6Nt6YkqRhRin0jcC9fctz3Vi/04HvTPKPSW5KcvG4AkqSRjP0kAuQAWM14H6eDbwE+DbgI0lurKo7H3ZHyW5gN8DmzZuXn1aStKhR9tDngNP6ljcB9w2Y86Gq+q+q+jxwPXDWwjuqqr1VNVtVszMzMyebWZI0wCiFfhDYlmRrklOAC4D9C+b8FfCCJOuTPA54DnDHeKNKkpYy9JBLVZ1IchlwHbAO2FdVh5Nc2q3fU1V3JPkQcCvwNeBdVXXbSgaXJD3cKMfQqaoDwIEFY3sWLL8dePv4okmSlsMzRSWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY0YqdCT7EhyJMnRJFcsMe+cJF9N8lPjiyhJGsXQQk+yDrgS2AlsBy5Msn2ReW8Drht3SEnScKPsoZ8LHK2qu6rqIeAaYNeAea8H/hw4NsZ8kqQRjVLoG4F7+5bnurGvS7IR+HFgz1J3lGR3kkNJDh0/fny5WSVJSxil0DNgrBYs/zZweVV9dak7qqq9VTVbVbMzMzMjRpQkjWL9CHPmgNP6ljcB9y2YMwtckwRgA3B+khNV9ZfjCClJGm6UQj8IbEuyFfgscAHwiv4JVbV1/naSq4G/scwlabKGFnpVnUhyGb1Pr6wD9lXV4SSXduuXPG4uSZqMUfbQqaoDwIEFYwOLvKp+7pHHkiQtl2eKSlIjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGjFSoSfZkeRIkqNJrhiw/qIkt3ZfNyQ5a/xRJUlLGVroSdYBVwI7ge3AhUm2L5h2N/CiqjoTeCuwd9xBJUlLG2UP/VzgaFXdVVUPAdcAu/onVNUNVfXFbvFGYNN4Y0qShhml0DcC9/Ytz3Vji7kE+OCgFUl2JzmU5NDx48dHTylJGmqUQs+AsRo4MXkxvUK/fND6qtpbVbNVNTszMzN6SknSUOtHmDMHnNa3vAm4b+GkJGcC7wJ2VtUD44knSRrVKHvoB4FtSbYmOQW4ANjfPyHJZuBa4JVVdef4Y0qShhm6h15VJ5JcBlwHrAP2VdXhJJd26/cAbwaeAlyVBOBEVc2uXGxJ0kKjHHKhqg4ABxaM7em7/RrgNeONJklaDs8UlaRGWOiS1IiRDrmsJe/76D0Dx1/xnM0TTiJJk+UeuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRjT3J+gW45+mk9Q699AlqREWuiQ1YqRCT7IjyZEkR5NcMWB9kvxOt/7WJGePP6okaSlDj6EnWQdcCfwwMAccTLK/qm7vm7YT2NZ9PQf4ve77quexdUmtGOVN0XOBo1V1F0CSa4BdQH+h7wLeU1UF3JjkSUlOrar7x554QhYr+uXyHwZJkzJKoW8E7u1bnuOb974HzdkIPKzQk+wGdneLX05yZFlpv2ED8PmT/NmV9E25LppSkAXWzPZaJcy1POYa3Tgyfc9iK0Yp9AwYq5OYQ1XtBfaO8JhLB0oOVdXsI72fcTPX8phrecy1PKsx10pnGuVN0TngtL7lTcB9JzFHkrSCRin0g8C2JFuTnAJcAOxfMGc/cHH3aZfnAl9ay8fPJWktGnrIpapOJLkMuA5YB+yrqsNJLu3W7wEOAOcDR4GvAK9eucjAGA7brBBzLY+5lsdcy7Mac61opvQ+mCJJWus8U1SSGmGhS1Ij1lyhD7sMwQo+7mlJ/iHJHUkOJ3lDN/6WJJ9NcnP3dX7fz/xal/NIkpetYLbPJPlE9/iHurEnJ/m7JJ/qvn/nJHMlOaNvm9yc5MEkb5zG9kqyL8mxJLf1jS17+yR5dredj3aXuhj0cd1HmuvtST7ZXULjL5I8qRvfkuS/+7bbngnnWvbzNqFcH+jL9JkkN3fjE9leS/TCdH6/qmrNfNF7U/bTwNOAU4BbgO0TeuxTgbO7208A7gS2A28BfmXA/O1dvscCW7vc61Yo22eADQvGfhO4ort9BfC2Seda8Lz9O70TIia+vYAXAmcDtz2S7QN8DHgevfMuPgjsXIFcLwXWd7ff1pdrS/+8BfcziVzLft4mkWvB+ncAb57k9mLxXpjK79da20P/+mUIquohYP4yBCuuqu6vqo93t/8TuIPe2bCL2QVcU1X/W1V30/sE0Lkrn/Rhj//u7va7gR+bYq6XAJ+uqn9bYs6K5aqq64EvDHi8kbdPklOBJ1bVR6r3f997+n5mbLmq6m+r6kS3eCO9czoWNalcS5jq9prX7c3+DPD+pe5j3LmW6IWp/H6ttUJf7BIDE5VkC/As4KPd0GXdS+R9fS+tJpm1gL9NclN6l1cA+K7qzgXovj91CrnmXcDD/0eb9vaC5W+fjd3tSeUD+Hl6e2rztib51yT/lOQF3dgkcy3neZv09noB8Lmq+lTf2ES314JemMrv11or9JEuMbCiAZLHA38OvLGqHqR3ZcmnA8+kd+2ad8xPHfDjK5X1B6rqbHpXvXxdkhcuMXei2zC9k9FeDvxpN7QattdSFssx6e32JuAE8N5u6H5gc1U9C/hl4H1JnjjBXMt93ib9fF7Iw3caJrq9BvTColMXefyx5FprhT7VSwwkeQy9J+29VXUtQFV9rqq+WlVfA/6AbxwmmFjWqrqv+34M+Isuw+e6l3HzLzOPTTpXZyfw8ar6XJdx6turs9ztM8fDD3+sWL4krwJ+BLioe/lN9xL9ge72TfSOvZ4+qVwn8bxNcnutB34C+EBf3oltr0G9wJR+v9ZaoY9yGYIV0R2j+0Pgjqr6rb7xU/um/Tgw/w78fuCCJI9NspXeteI/tgK5vj3JE+Zv03tT7bbu8V/VTXsV8FeTzNXnYXtO095efZa1fbqXzf+Z5Lnd78LFfT8zNkl2AJcDL6+qr/SNz6T3twlI8rQu110TzLWs521SuTo/BHyyqr5+yGJS22uxXmBav18n++7utL7oXWLgTnr/4r5pgo/7fHovgW4Fbu6+zgf+CPhEN74fOLXvZ97U5TzCI3yHf4lcT6P3rvktwOH5bQI8Bfh74FPd9ydPMlf3OI8DHgC+o29s4tuL3j8o9wP/R29P6JKT2T7ALL0i+zTwTrozrcec6yi9Y6zzv2N7urk/2T2/twAfB350wrmW/bxNIlc3fjVw6YK5E9leLN4LU/n98tR/SWrEWjvkIklahIUuSY2w0CWpERa6JDXCQpekRljoUp8kv5Hkh6adQzoZfmxR6iRZV1VfnXYO6WS5h65Hhe762J9M8u7uAlN/luRx6V1D+81J/gX46SRXJ/mp7mfOSXJDkluSfCzJE5KsS++a5Qe7+/mFKf+nSV9noevR5Axgb1WdCTwI/FI3/j9V9fyqumZ+YndpiQ8Ab6iqs+idXv7f9M6a/FJVnQOcA7y2O4VbmjoLXY8m91bVh7vbf0zvtG3ou6hTnzOA+6vqIEBVPVi965S/FLg4vb+M81F6p3hvW9HU0ojWTzuANEEL3zCaX/6vAXMzYP78+Our6rpxBpPGwT10PZpsTvK87vaFwL8sMfeTwHcnOQegO36+HrgO+MXukqkkOb27yqU0dRa6Hk3uAF6V5FbgyfT+aMNA1fsThz8L/G6SW4C/A74VeBdwO/Dx9P5Y8e/jK12tEn5sUY8K3Z8H+5uqesa0s0grxT10SWqEe+iS1Aj30CWpERa6JDXCQpekRljoktQIC12SGvH/GzDXj9gA/ikAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "y_train_df=mercari_df['price']\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.distplot(y_train_df,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='price'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 로그값으로 변환\n",
    "import numpy as np\n",
    "\n",
    "y_train_df=np.log1p(y_train_df)\n",
    "sns.distplot(y_train_df,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.397895\n",
       "1    3.970292\n",
       "2    2.397895\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mercari_df['price']=np.log1p(mercari_df['price'])\n",
    "mercari_df['price'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shipping 값 유형 : \n",
      " 0    819435\n",
      "1    663100\n",
      "Name: shipping, dtype: int64\n",
      "item_condition_id 값 유형 : \n",
      " 1    640549\n",
      "3    432161\n",
      "2    375479\n",
      "4     31962\n",
      "5      2384\n",
      "Name: item_condition_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Shipping 값 유형 : \\n',mercari_df['shipping'].value_counts())\n",
    "print('item_condition_id 값 유형 : \\n',mercari_df['item_condition_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82489"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_cond=mercari_df['item_description']=='No description yet'\n",
    "mercari_df[boolean_cond]['item_description'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대분류 유형 : \n",
      " Women                     664385\n",
      "Beauty                    207828\n",
      "Kids                      171689\n",
      "Electronics               122690\n",
      "Men                        93680\n",
      "Home                       67871\n",
      "Vintage & Collectibles     46530\n",
      "Other                      45351\n",
      "Handmade                   30842\n",
      "Sports & Outdoors          25342\n",
      "Other_Null                  6327\n",
      "Name: cat_dae, dtype: int64\n",
      "중분류 갯수 : 114\n",
      "소분류 갯수 : 871\n"
     ]
    }
   ],
   "source": [
    "# apply lambda에서 호출되는 대,중,소 분할함수 생성\n",
    "def split_cat(category_name):\n",
    "    try:\n",
    "        return category_name.split('/')\n",
    "    except:\n",
    "        return ['Other_Null' , 'Other_Null' , 'Other_Null']\n",
    "    \n",
    "# 위의 split_cat( )을 apply lambda에서 호출하여 대,중,소 컬럼을 mercari_df에 생성. \n",
    "mercari_df['cat_dae'], mercari_df['cat_jung'],mercari_df['cat_so']= zip(*mercari_df['category_name'].apply(lambda x : split_cat(x)))\n",
    "\n",
    "# 대분류만 값의 유형과 건수를 살펴보고, 중분류, 소분류는 값의 유형이 많으므로 분류 갯수만 추출\n",
    "print('대분류 유형 : \\n',mercari_df['cat_dae'].value_counts())\n",
    "print('중분류 갯수 :', mercari_df['cat_jung'].nunique())\n",
    "print('소분류 갯수 :', mercari_df['cat_so'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_id             0\n",
       "name                 0\n",
       "item_condition_id    0\n",
       "category_name        0\n",
       "brand_name           0\n",
       "price                0\n",
       "shipping             0\n",
       "item_description     0\n",
       "cat_dae              0\n",
       "cat_jung             0\n",
       "cat_so               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mercari_df['brand_name']=mercari_df['brand_name'].fillna(value='Other_Null')\n",
    "mercari_df['category_name']=mercari_df['category_name'].fillna(value='Other_Null')\n",
    "mercari_df['item_description']=mercari_df['item_description'].fillna(value='Other_Null')\n",
    "\n",
    "# 각 칼럼별로 Null값 건수 확인, 모두 0이 나와야 함\n",
    "mercari_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 피처 인코딩, 피처 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand name의 유형 건수 :  4810\n",
      "brand name sample 5건 : \n",
      " Other_Null           632682\n",
      "PINK                  54088\n",
      "Nike                  54043\n",
      "Victoria's Secret     48036\n",
      "LuLaRoe               31024\n",
      "Name: brand_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('brand name의 유형 건수 : ',mercari_df['brand_name'].nunique())\n",
    "print('brand name sample 5건 : \\n',mercari_df['brand_name'].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name의 종류 개수 :  1225273\n",
      "name sample 7건 : \n",
      " 0    MLB Cincinnati Reds T Shirt Size XL\n",
      "1       Razer BlackWidow Chroma Keyboard\n",
      "2                         AVA-VIV Blouse\n",
      "3                  Leather Horse Statues\n",
      "4                   24K GOLD plated rose\n",
      "5       Bundled items requested for Ruie\n",
      "6     Acacia pacific tides santorini top\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('name의 종류 개수 : ', mercari_df['name'].nunique())\n",
    "print('name sample 7건 : \\n',mercari_df['name'][:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_description 평균 문자열 개수 :  145.7113889385411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                              No description yet\n",
       "1    This keyboard is in great condition and works like it came out of the box. All of the ports are tested and work perfectly. The lights are customizable via the Razer Synapse app on your PC.\n",
       "Name: item_description, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth',200) # pandas 설정 바꾸기\n",
    "\n",
    "# item_description의 평균 문자열 개수 \n",
    "print('item_description 평균 문자열 개수 : ',mercari_df['item_description'].str.len().mean())\n",
    "\n",
    "mercari_df['item_description'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name vectorization shape :  (1482535, 105757)\n",
      "item_description vectorization shape :  (1482535, 50000)\n"
     ]
    }
   ],
   "source": [
    "# name 속성에 대한 feature vectorization 변환\n",
    "cnt_vec=CountVectorizer()\n",
    "X_name=cnt_vec.fit_transform(mercari_df.name)\n",
    "\n",
    "# item_description에 대한 feature vectorization 변환\n",
    "tfidf_descp=TfidfVectorizer(max_features=50000, ngram_range=(1,3), stop_words='english')\n",
    "X_descp=tfidf_descp.fit_transform(mercari_df['item_description'])\n",
    "\n",
    "print('name vectorization shape : ',X_name.shape)\n",
    "print('item_description vectorization shape : ',X_descp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# brand_name, item_condition_id, shipping 각 피처들을 희소 행렬 원-핫 인코딩 변환\n",
    "lb_brand_name= LabelBinarizer(sparse_output=True)\n",
    "X_brand = lb_brand_name.fit_transform(mercari_df['brand_name'])\n",
    "\n",
    "lb_item_cond_id = LabelBinarizer(sparse_output=True)\n",
    "X_item_cond_id = lb_item_cond_id.fit_transform(mercari_df['item_condition_id'])\n",
    "\n",
    "lb_shipping= LabelBinarizer(sparse_output=True)\n",
    "X_shipping = lb_shipping.fit_transform(mercari_df['shipping'])\n",
    "\n",
    "# cat_dae, cat_jung, cat_so 각 피처들을 희소 행렬 원-핫 인코딩 변환\n",
    "lb_cat_dae = LabelBinarizer(sparse_output=True)\n",
    "X_cat_dae= lb_cat_dae.fit_transform(mercari_df['cat_dae'])\n",
    "\n",
    "lb_cat_jung = LabelBinarizer(sparse_output=True)\n",
    "X_cat_jung = lb_cat_jung.fit_transform(mercari_df['cat_jung'])\n",
    "\n",
    "lb_cat_so = LabelBinarizer(sparse_output=True)\n",
    "X_cat_so = lb_cat_so.fit_transform(mercari_df['cat_so'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> <class 'scipy.sparse.csr.csr_matrix'> <class 'scipy.sparse.csr.csr_matrix'>\n",
      "X_brand_shape:(1482535, 4810), X_item_cond_id shape:(1482535, 5)\n",
      "X_shipping shape:(1482535, 1), X_cat_dae shape:(1482535, 11)\n",
      "X_cat_jung shape:(1482535, 114), X_cat_so shape:(1482535, 871)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_brand), type(X_item_cond_id), type(X_shipping))\n",
    "print('X_brand_shape:{0}, X_item_cond_id shape:{1}'.format(X_brand.shape, X_item_cond_id.shape))\n",
    "print('X_shipping shape:{0}, X_cat_dae shape:{1}'.format(X_shipping.shape, X_cat_dae.shape))\n",
    "print('X_cat_jung shape:{0}, X_cat_so shape:{1}'.format(X_cat_jung.shape, X_cat_so.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (1482535, 161569)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "import gc\n",
    "\n",
    "sparse_matrix_list=(X_name,X_descp,X_brand,X_item_cond_id,X_shipping,X_cat_dae,X_cat_jung,X_cat_so)\n",
    "\n",
    "# 사이파이 sparse 모듈의 hstack 함수를 이용하여 앞에서 인코딩과 Vectorization을 수행한 데이터 셋을 모두 결합. \n",
    "X_features_sparse=hstack(sparse_matrix_list).tocsr()\n",
    "print(type(X_features_sparse),X_features_sparse.shape)\n",
    "\n",
    "# 데이터 셋이 메모리를 많이 차지하므로 사용 용도가 끝났으면 바로 메모리에서 삭제.\n",
    "del X_features_sparse\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 릿지 회귀 모델 구축 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y , y_pred):\n",
    "    # underflow, overflow를 막기 위해 log가 아닌 log1p로 rmsle 계산 \n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y) - np.log1p(y_pred), 2)))\n",
    "\n",
    "def evaluate_org_price(y_test , preds): \n",
    "    \n",
    "    # 원본 데이터는 log1p로 변환되었으므로 exmpm1으로 원복 필요. \n",
    "    preds_exmpm = np.expm1(preds)\n",
    "    y_test_exmpm = np.expm1(y_test)\n",
    "    \n",
    "    # rmsle로 RMSLE 값 추출\n",
    "    rmsle_result = rmsle(y_test_exmpm, preds_exmpm)\n",
    "    return rmsle_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def model_train_predict(model,matrix_list):\n",
    "    # scipy.sparse 모듈으 ㅣhstack을 이용하여 sparse matrix 결합\n",
    "    X=hstack(matrix_list).tocsr()\n",
    "    \n",
    "    X_train,X_test,y_train,y_test=train_test_split(X, mercari_df['price'],test_size=0.2,random_state=156)\n",
    "    \n",
    "    # 모델 및 학습 예측\n",
    "    model.fit(X_train,y_train)\n",
    "    preds=model.predict(X_test)\n",
    "    \n",
    "    del X,X_train,X_test,y_train\n",
    "    gc.collect()\n",
    "    \n",
    "    return preds,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Description을 제외했을때 rmsle 값 :  0.5021755915142884\n",
      "Item Description을 포함한 rmsle 값 :  0.4712200512893522\n"
     ]
    }
   ],
   "source": [
    "linear_model=Ridge(solver='lsqr',fit_intercept=False)\n",
    "\n",
    "sparse_matrix_list = (X_name, X_brand, X_item_cond_id,\n",
    "                      X_shipping, X_cat_dae, X_cat_jung, X_cat_so)\n",
    "linear_preds,y_test=model_train_predict(model=linear_model,matrix_list=sparse_matrix_list)\n",
    "print('Item Description을 제외했을때 rmsle 값 : ',evaluate_org_price(y_test,linear_preds))\n",
    "\n",
    "sparse_matrix_list = (X_descp, X_name, X_brand, X_item_cond_id,\n",
    "                      X_shipping, X_cat_dae, X_cat_jung, X_cat_so)\n",
    "linear_preds,y_test=model_train_predict(model=linear_model,matrix_list=sparse_matrix_list)\n",
    "print('Item Description을 포함한 rmsle 값 : ',evaluate_org_price(y_test,linear_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM rmsle 값: 0.45717396513530145\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "sparse_matrix_list=(X_descp,X_name,X_brand,X_item_cond_id,X_shipping,X_cat_dae,X_cat_jung,X_cat_so)\n",
    "\n",
    "lgbm_model=LGBMRegressor(n_estimators=200, learning_rate=0.5,num_leaves=125,random_state=156)\n",
    "lgbm_preds,y_test=model_train_predict(model=lgbm_model,matrix_list=sparse_matrix_list)\n",
    "print('LightGBM rmsle 값:',  evaluate_org_price(y_test , lgbm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM과 Ridge를 ensemble한 최종 rmsle 값 :  0.4507426106676606\n"
     ]
    }
   ],
   "source": [
    "preds=lgbm_preds*0.45 + linear_preds*0.55\n",
    "print('LightGBM과 Ridge를 ensemble한 최종 rmsle 값 : ',evaluate_org_price(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
